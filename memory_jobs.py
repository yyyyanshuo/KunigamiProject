import os
import json
import sqlite3
import datetime
from datetime import timedelta
from app import call_ai_to_summarize

# å®šä¹‰è·¯å¾„
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROMPTS_DIR = os.path.join(BASE_DIR, "prompts")
SHORT_FILE = os.path.join(PROMPTS_DIR, "6_memory_short.json")
MEDIUM_FILE = os.path.join(PROMPTS_DIR, "5_memory_medium.json")
LONG_FILE = os.path.join(PROMPTS_DIR, "4_memory_long.json")
DATABASE_FILE = os.path.join(BASE_DIR, "chat_history.db") # æ•°æ®åº“è·¯å¾„

def auto_snapshot_from_db(target_date_str):
    """
    ã€æ–°å¢ã€‘ä»æ•°æ®åº“è¯»å–æŒ‡å®šæ—¥æœŸçš„èŠå¤©ï¼Œè‡ªåŠ¨ç”ŸæˆçŸ­æœŸè®°å¿†
    """
    print(f"   -> æ­£åœ¨ä»æ•°æ®åº“è¡¥å½• {target_date_str} çš„è®°å¿†...")

    start_time = f"{target_date_str} 00:00:00"
    end_time = f"{target_date_str} 23:59:59"

    conn = sqlite3.connect(DATABASE_FILE)
    cursor = conn.cursor()
    cursor.execute("SELECT timestamp, role, content FROM messages WHERE timestamp >= ? AND timestamp <= ?", (start_time, end_time))
    rows = cursor.fetchall()
    conn.close()

    if not rows:
        print("   -> æ•°æ®åº“é‡Œè¿™ä¸€å¤©ä¹Ÿæ²¡èŠè¿‡å¤©ï¼Œå½»åº•è·³è¿‡ã€‚")
        return None

    # æ‹¼å‡‘æ–‡æœ¬
    chat_log = ""
    for ts, role, content in rows:
        time_part = ts.split(' ')[1][:5]
        name = "ç”¨æˆ·" if role == "user" else "æˆ‘"
        chat_log += f"[{time_part}] {name}: {content}\n"

    # è°ƒç”¨ AI
    summary_text = call_ai_to_summarize(chat_log, "short")
    if not summary_text: return None

    # è§£æ
    events = []
    import re
    for line in summary_text.split('\n'):
        line = line.strip()
        if line:
            match_time = re.search(r'\[(\d{2}:\d{2})\]', line)
            event_time = match_time.group(1) if match_time else "00:00"
            event_text = re.sub(r'\[\d{2}:\d{2}\]', '', line).strip('- ').strip()
            events.append({"time": event_time, "event": event_text})

    return events

def process_daily_rollover(target_date_str=None):
    # é»˜è®¤å¤„ç†æ˜¨å¤©
    if not target_date_str:
        target_date_str = (datetime.datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')

    print(f"â° [å®šæ—¶ä»»åŠ¡] å¼€å§‹æ—¥ç»“: {target_date_str}")

    # 1. è¯»å–ç°æœ‰çš„ Short Memory
    short_data = {}
    if os.path.exists(SHORT_FILE):
        with open(SHORT_FILE, "r", encoding="utf-8") as f:
            try: short_data = json.load(f)
            except: pass

    # 2. æ£€æŸ¥æ˜¨å¤©æœ‰æ²¡æœ‰è®°å½•ï¼Œå¦‚æœæ²¡æœ‰ï¼Œè‡ªåŠ¨è¡¥å½•ï¼(Auto-Snapshot)
    events = short_data.get(target_date_str)

    if not events:
        print(f"   - {target_date_str} æœªå‘ç°æ‰‹åŠ¨æ•´ç†çš„è®°å¿†ï¼Œå°è¯•è‡ªåŠ¨è¡¥å½•...")
        events = auto_snapshot_from_db(target_date_str)
        if events:
            # è¡¥å½•æˆåŠŸï¼Œä¿å­˜å› Short æ–‡ä»¶ï¼Œæ–¹ä¾¿äººç±»æŸ¥çœ‹
            short_data[target_date_str] = events
            with open(SHORT_FILE, "w", encoding="utf-8") as f:
                json.dump(short_data, f, ensure_ascii=False, indent=2)
            print("   - âœ… è‡ªåŠ¨è¡¥å½•æˆåŠŸï¼")
        else:
            print("   - âŒ è¡¥å½•å¤±è´¥æˆ–æ— å¯¹è¯ï¼Œç»“æŸæ—¥ç»“ã€‚")
            return

    # 3. å¼€å§‹æ—¥ç»“ (Short -> Medium)
    text_to_summarize = "\n".join([f"[{e['time']}] {e['event']}" for e in events])
    summary = call_ai_to_summarize(text_to_summarize, "medium")

    if not summary: return

    # 4. å†™å…¥ Medium
    medium_data = {}
    if os.path.exists(MEDIUM_FILE):
        with open(MEDIUM_FILE, "r", encoding="utf-8") as f:
            try: medium_data = json.load(f)
            except: pass

    medium_data[target_date_str] = summary

    with open(MEDIUM_FILE, "w", encoding="utf-8") as f:
        json.dump(medium_data, f, ensure_ascii=False, indent=2)

    print("   - ğŸ“ æ—¥ç»“(Medium)å†™å…¥å®Œæˆã€‚")

def process_weekly_rollover():
    print("â° [å®šæ—¶ä»»åŠ¡] å¼€å§‹å‘¨ç»“...")
    if not os.path.exists(MEDIUM_FILE): return

    with open(MEDIUM_FILE, "r", encoding="utf-8") as f:
        try: medium_data = json.load(f)
        except: return

    today = datetime.datetime.now()
    summary_buffer = []

    # è¿‡å»7å¤©
    for i in range(7):
        d = (today - timedelta(days=i)).strftime('%Y-%m-%d')
        if d in medium_data:
            summary_buffer.append(f"ã€{d}ã€‘: {medium_data[d]}")

    if not summary_buffer: return

    full_text = "\n".join(summary_buffer)
    long_summary = call_ai_to_summarize(full_text, "long")

    if not long_summary: return

    week_key = f"{today.strftime('%Y-%m')}-Week{ (today.day - 1) // 7 + 1}"

    long_data = {}
    if os.path.exists(LONG_FILE):
        with open(LONG_FILE, "r", encoding="utf-8") as f:
            try: long_data = json.load(f)
            except: pass

    long_data[week_key] = long_summary

    with open(LONG_FILE, "w", encoding="utf-8") as f:
        json.dump(long_data, f, ensure_ascii=False, indent=2)

    print("   - ğŸ“œ å‘¨ç»“(Long)å†™å…¥å®Œæˆã€‚")