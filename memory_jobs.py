import os
import json
import datetime
from datetime import timedelta
import time

# è¿™é‡Œçš„å¼•ç”¨éå¸¸å…³é”®
# æˆ‘ä»¬ä» app å¯¼å…¥ AI æ€»ç»“åŠŸèƒ½ å’Œ å¢é‡æ›´æ–°åŠŸèƒ½
from app import call_ai_to_summarize, update_short_memory_for_date

# å®šä¹‰åŸºç¡€è·¯å¾„
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CONFIG_FILE = os.path.join(BASE_DIR, "configs", "characters.json")

# --- è¾…åŠ©å‡½æ•°ï¼šè·å–æŒ‡å®šè§’è‰²çš„ Prompt è·¯å¾„ ---
def get_char_prompts_dir(char_id):
    return os.path.join(BASE_DIR, "characters", char_id, "prompts")

# --- è¾…åŠ©å‡½æ•°ï¼šè·å–æ‰€æœ‰è§’è‰² ID ---
def get_all_char_ids():
    if not os.path.exists(CONFIG_FILE):
        print(f"âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {CONFIG_FILE}")
        return []
    try:
        with open(CONFIG_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            return list(data.keys())
    except:
        return []

# ================= æ—¥ç»“é€»è¾‘ (Daily) =================

def _process_single_char_daily(char_id, target_date_str):
    """å¤„ç†å•ä¸ªè§’è‰²çš„æ—¥ç»“"""
    print(f"   > æ­£åœ¨å¤„ç†è§’è‰²: [{char_id}]")

    prompts_dir = get_char_prompts_dir(char_id)
    short_file = os.path.join(prompts_dir, "6_memory_short.json")
    medium_file = os.path.join(prompts_dir, "5_memory_medium.json")

    # --- 1. è‡ªåŠ¨è¡¥æ¼ (è°ƒç”¨ app.py çš„å‡½æ•°) ---
    try:
        # æ³¨æ„ï¼šè¿™é‡Œçš„ update_short_memory_for_date å¿…é¡»åœ¨ app.py é‡Œæ”¯æŒ char_id å‚æ•°
        count, _ = update_short_memory_for_date(char_id, target_date_str)
        if count > 0:
            print(f"     âœ… [è¡¥å½•] è‡ªåŠ¨è¡¥å½•äº† {count} æ¡è®°å¿†")
    except Exception as e:
        print(f"     âŒ [è¡¥å½•] å‡ºé”™: {e}")

    # --- 2. ç”Ÿæˆæ—¥è®° (Short -> Medium) ---
    if not os.path.exists(short_file):
        print("     - æ— çŸ­æœŸè®°å¿†æ–‡ä»¶ï¼Œè·³è¿‡")
        return

    with open(short_file, "r", encoding="utf-8") as f:
        try: short_data = json.load(f)
        except: return

    # å…¼å®¹æ–°æ—§æ ¼å¼è·å–äº‹ä»¶
    day_data = short_data.get(target_date_str)
    events = []
    if isinstance(day_data, list):
        events = day_data
    elif isinstance(day_data, dict):
        events = day_data.get("events", [])

    if not events:
        print(f"     - {target_date_str} æ— äº‹ä»¶è®°å½•ï¼Œè·³è¿‡æ—¥ç»“")
        return

    # æ‹¼å‡‘æ–‡æœ¬
    text_to_summarize = "\n".join([f"[{e['time']}] {e['event']}" for e in events])

    # è°ƒç”¨ AI (æ³¨æ„ï¼šè¿™é‡Œå¦‚æœæ˜¯å¤šè§’è‰²ï¼ŒAI å¯èƒ½ä¼šæ ¹æ® System Prompt é‡Œçš„è®¾å®šæ¥å†™æ—¥è®°)
    # ä¸ºäº†ä¿è¯äººè®¾ä¸ä¸²ï¼Œç†æƒ³æƒ…å†µä¸‹åº”è¯¥æŠŠ char_id ä¼ ç»™ call_ai_to_summarize æ¥åˆ‡æ¢ System Prompt
    # ä½†ç›®å‰ call_ai_to_summarize æ˜¯é€šç”¨çš„ï¼Œæˆ‘ä»¬å…ˆè¿™æ ·ç”¨
    summary = call_ai_to_summarize(text_to_summarize, "medium", char_id)

    if not summary:
        print("     âš ï¸ AI è¿”å›ä¸ºç©ºï¼Œæ—¥ç»“å¤±è´¥")
        return

    # å†™å…¥ Medium
    medium_data = {}
    if os.path.exists(medium_file):
        with open(medium_file, "r", encoding="utf-8") as f:
            try: medium_data = json.load(f)
            except: pass

    medium_data[target_date_str] = summary

    with open(medium_file, "w", encoding="utf-8") as f:
        json.dump(medium_data, f, ensure_ascii=False, indent=2)

    print("     ğŸ“ æ—¥è®°å†™å…¥å®Œæˆ")


def run_all_daily_rollovers(target_date_str=None):
    """ã€å…¥å£ã€‘éå†æ‰€æœ‰è§’è‰²æ‰§è¡Œæ—¥ç»“"""
    if not target_date_str:
        target_date_str = (datetime.datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')

    print(f"â° [å®šæ—¶ä»»åŠ¡] å¼€å§‹å…¨å‘˜æ—¥ç»“: {target_date_str}")

    char_ids = get_all_char_ids()
    for char_id in char_ids:
        try:
            _process_single_char_daily(char_id, target_date_str)
            # ä¼‘æ¯ä¸€ä¸‹ï¼Œé˜²æ­¢å¹¶å‘è¯·æ±‚å¤ªå¤šè¢«å°å·
            time.sleep(2)
        except Exception as e:
            print(f"     âŒ å¤„ç†è§’è‰² {char_id} æ—¶å´©æºƒ: {e}")

    print("âœ… å…¨å‘˜æ—¥ç»“ç»“æŸã€‚")


# ================= å‘¨ç»“é€»è¾‘ (Weekly) =================

def _process_single_char_weekly(char_id):
    """å¤„ç†å•ä¸ªè§’è‰²çš„å‘¨ç»“"""
    print(f"   > æ­£åœ¨å¤„ç†è§’è‰²: [{char_id}] (å‘¨ç»“)")

    prompts_dir = get_char_prompts_dir(char_id)
    medium_file = os.path.join(prompts_dir, "5_memory_medium.json")
    long_file = os.path.join(prompts_dir, "4_memory_long.json")

    if not os.path.exists(medium_file): return

    with open(medium_file, "r", encoding="utf-8") as f:
        try: medium_data = json.load(f)
        except: return

    today = datetime.datetime.now()
    summary_buffer = []

    # è¿‡å»7å¤©
    for i in range(7):
        d = (today - timedelta(days=i)).strftime('%Y-%m-%d')
        if d in medium_data:
            summary_buffer.append(f"ã€{d}ã€‘: {medium_data[d]}")

    if not summary_buffer:
        print("     - è¿‘7å¤©æ— æ—¥è®°ï¼Œè·³è¿‡")
        return

    full_text = "\n".join(summary_buffer)
    long_summary = call_ai_to_summarize(full_text, "long", char_id)

    if not long_summary: return

    # è®¡ç®— Week Key (ä»¥æ˜¨å¤©/å‘¨æ—¥ä¸ºå‡†)
    target_sunday = today - timedelta(days=1)
    target_month_str = target_sunday.strftime('%Y-%m')
    week_num = (target_sunday.day - 1) // 7 + 1
    week_key = f"{target_month_str}-Week{week_num}"

    long_data = {}
    if os.path.exists(long_file):
        with open(long_file, "r", encoding="utf-8") as f:
            try: long_data = json.load(f)
            except: pass

    long_data[week_key] = long_summary

    with open(long_file, "w", encoding="utf-8") as f:
        json.dump(long_data, f, ensure_ascii=False, indent=2)

    print(f"     ğŸ“œ å‘¨æŠ¥å†™å…¥å®Œæˆ: {week_key}")


def run_all_weekly_rollovers():
    """ã€å…¥å£ã€‘éå†æ‰€æœ‰è§’è‰²æ‰§è¡Œå‘¨ç»“"""
    print("â° [å®šæ—¶ä»»åŠ¡] å¼€å§‹å…¨å‘˜å‘¨ç»“...")

    char_ids = get_all_char_ids()
    for char_id in char_ids:
        try:
            _process_single_char_weekly(char_id)
            time.sleep(2)
        except Exception as e:
            print(f"     âŒ å¤„ç†è§’è‰² {char_id} æ—¶å´©æºƒ: {e}")

    print("âœ… å…¨å‘˜å‘¨ç»“ç»“æŸã€‚")